{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4aad2a78",
      "metadata": {
        "id": "4aad2a78"
      },
      "source": [
        "# Exercise 02: Regular Expressions and the Natural Language Toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63068b6",
      "metadata": {
        "id": "c63068b6"
      },
      "source": [
        "### Task 1: Regular Expressions\n",
        "In this task we're working with the `re` package of Python. Take a look at the documentation to solve the following subtasks: https://docs.python.org/3/library/re.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "695a3878",
      "metadata": {
        "id": "695a3878"
      },
      "outputs": [],
      "source": [
        "# import the re package\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce209f79",
      "metadata": {
        "id": "ce209f79"
      },
      "source": [
        "Make yourself familiar with the different kinds of regex commands `re.XXXX(pattern, string)` available in python. Describe the differences between them.\n",
        "\n",
        "* re.search()\n",
        "* re.match()\n",
        "* re.fullmatch()\n",
        "* re.split()\n",
        "* re.findall()\n",
        "* re.finditer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51abed78",
      "metadata": {
        "id": "51abed78",
        "outputId": "cc28f4c4-557d-4e33-cd5b-ac46d3c44296"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "search() missing 2 required positional arguments: 'pattern' and 'string'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-961acc60e4db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: search() missing 2 required positional arguments: 'pattern' and 'string'"
          ]
        }
      ],
      "source": [
        "re.search()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3860f2dc",
      "metadata": {
        "id": "3860f2dc"
      },
      "source": [
        "__a)__ Write a regular expression that checks if \"Hello World\" is contained in a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd13993",
      "metadata": {
        "id": "dbd13993"
      },
      "outputs": [],
      "source": [
        "positive = \"this is a Hello World test \"\n",
        "negative = \"this is a H3ll0 W0rld Test \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19cd78a",
      "metadata": {
        "id": "b19cd78a",
        "outputId": "313c267f-1235-4718-8fcc-a5369e2788cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Hello World' is not contained in a string\n"
          ]
        }
      ],
      "source": [
        "result = re.search(\"Hello World\", negative)\n",
        "if result:\n",
        "    print(\"'Hello World' is contained in the string\")\n",
        "else:\n",
        "    print(\"'Hello World' is not contained in the string\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8fb00d7",
      "metadata": {
        "id": "d8fb00d7"
      },
      "source": [
        "__b)__ Write a regular expression that selects all integer numbers from a text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc73173",
      "metadata": {
        "id": "bbc73173"
      },
      "outputs": [],
      "source": [
        "s1 = \"This is a text written in 2022, and it contains numbers like one, 2, 3. Other numbers like 123 are also detected.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4386d29",
      "metadata": {
        "id": "b4386d29",
        "outputId": "687ab93d-7f7e-49d6-af62-6a670ad08660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2022', '2', '3', '123']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall(r\"\\d+\", s1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1876c6cf",
      "metadata": {
        "id": "1876c6cf"
      },
      "source": [
        "__c)__ Write a regular expression that finds two (lower-case) words connected by a \"-\" (e.g., ill-advised)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62eef05c",
      "metadata": {
        "id": "62eef05c"
      },
      "outputs": [],
      "source": [
        "s2 = \"This my so-so example text. It features well-received meaningless words. The string 1-2 should not be returned.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4093655a",
      "metadata": {
        "id": "4093655a",
        "outputId": "654516b1-a0a9-4895-ec59-62310eeb3352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['so-so', 'well-received']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall(r'[a-z]+-[a-z]+', s2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bdeeea1",
      "metadata": {
        "id": "7bdeeea1"
      },
      "source": [
        "__d)__ Write a regular expression that selects numbers with at least 4 digits from a text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfcdb82b",
      "metadata": {
        "id": "cfcdb82b"
      },
      "outputs": [],
      "source": [
        "s3 = \"This is a 2022 text, the third useless text I'm writing after 2021 ended. Larger numbers like 63527 should be detected, but smaller numbers like 123 should not.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6f5a2f",
      "metadata": {
        "id": "eb6f5a2f",
        "outputId": "f806f9a3-2eb2-4970-c8b2-0ce526636a7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2022', '2021', '63527']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall(r\"\\d{4,}\", s3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf603d7",
      "metadata": {
        "id": "bbf603d7"
      },
      "source": [
        "__d)__ Write a regular expression that extract dates in the format YYYY-MM-DD:\n",
        "Assume that Y, M or D are valid when they are digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4641c2b1",
      "metadata": {
        "id": "4641c2b1"
      },
      "outputs": [],
      "source": [
        "s4 = \"2017-05-12 and 2018-01-01 are correct formats,  2017-25-01 is also valid. Not valid is 03.05.22, neither is 12/12/2017.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d814c49b",
      "metadata": {
        "id": "d814c49b",
        "outputId": "d4ef9109-7254-41b3-bcd8-22b7eea11512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2017-05-12', '2018-01-01', '2017-25-01']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall(r'\\d{4}-\\d{2}-\\d{2}', s4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8eded5f",
      "metadata": {
        "id": "f8eded5f"
      },
      "source": [
        "__e)__ Write a regular expression that finds all URLS in a string. For sake of simplicity, a url starts with \"http://\" or \"https://\" and contains at least one dot, which is not at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d61158c2",
      "metadata": {
        "id": "d61158c2"
      },
      "outputs": [],
      "source": [
        "s5 = \"The url http://example1.com should be returned, as well as http://www.example2.com. Let's try http://test.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B4qL7ldvOBuX"
      },
      "id": "B4qL7ldvOBuX"
    },
    {
      "cell_type": "code",
      "source": [
        "s5 = \"The url http://www.exa..mple1.com should be returned, as well as https://www.exam-ple2.com. Let's try http://test. http://wwwexa..mple1/djei.com. and also https://colab.research.google.com/github/andy7622y/myfb/blob/main/IS661/02e_done__regex_nltk_tasks.ipynb#scrollTo=-0Kq0BTQPNja\"\n",
        "\n"
      ],
      "metadata": {
        "id": "OrSrbdTUODSq"
      },
      "id": "OrSrbdTUODSq",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea45252",
      "metadata": {
        "id": "5ea45252"
      },
      "outputs": [],
      "source": [
        "#.group() 的行为：\n",
        "#m.group() 或 m.group(0)：返回整个匹配的字符串，即正则表达式匹配到的完整 URL。\n",
        "#m.group(1)：返回第一个捕获组的内容（括号 () 内的部分）。在这个例子中，m.group(1) 返回的是域名部分，比如 example.com。\n",
        "\n",
        "#[\\w.-]+：匹配任意字母、数字、下划线、点号和破折号的组合。这能捕获包含多个点号的完整域名。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https?://[^\\s]+\\.[^\\s\\.]\n",
        ".^\\.+[^\\s\\.]\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ShjvxlWTFoVu"
      },
      "id": "ShjvxlWTFoVu"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DS3Kf0cgIZYI"
      },
      "id": "DS3Kf0cgIZYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(?:www\\.)?[^\\s]+\\.\\w+\n",
        "\\/\\/"
      ],
      "metadata": {
        "id": "-YNc89yBIZzB"
      },
      "id": "-YNc89yBIZzB"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "15e77fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15e77fec",
        "outputId": "767e0cd8-8292-4d41-ad51-e2f6e1c53919"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://www.exa..mple1.com',\n",
              " 'https://www.exam-ple2.com.',\n",
              " 'http://test.',\n",
              " 'http://wwwexa..mple1',\n",
              " 'https://colab.research.google.com']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pattern5 = r'https?://[\\w.-]+'\n",
        "re.findall(pattern5, s5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern7 = r'https?://[.\\w/-]+\\.\\w+'\n",
        "re.findall(pattern7, s5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-D194LqOL6Z",
        "outputId": "8c4c6a99-1af0-4299-c30d-46d19964e1c3"
      },
      "id": "6-D194LqOL6Z",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://www.exa..mple1.com',\n",
              " 'https://www.exam-ple2.com',\n",
              " 'http://wwwexa..mple1/djei.com',\n",
              " 'https://colab.research.google.com/github/andy7622y/myfb/blob/main/IS661/02e_done__regex_nltk_tasks.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern8 = r'https?://[^\\s]+[^\\s\\.]'\n",
        "re.findall(pattern8, s5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Kq0BTQPNja",
        "outputId": "29528f77-252b-45af-ccfb-b245d3c65047"
      },
      "id": "-0Kq0BTQPNja",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://www.exa..mple1.com',\n",
              " 'https://www.exam-ple2.com',\n",
              " 'http://test',\n",
              " 'http://wwwexa..mple1/djei.com',\n",
              " 'https://colab.research.google.com/github/andy7622y/myfb/blob/main/IS661/02e_done__regex_nltk_tasks.ipynb#scrollTo=-0Kq0BTQPNja']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d35428",
      "metadata": {
        "id": "13d35428"
      },
      "source": [
        "__f)__ Replace all occurences of _two_ as whole word with _2_ in a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b27cc88",
      "metadata": {
        "id": "7b27cc88"
      },
      "outputs": [],
      "source": [
        "s6 = \"An easy math task is two + 3 = 5. The infix two in the word twofold should remain unchanged, though.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9850e5d4",
      "metadata": {
        "id": "9850e5d4",
        "outputId": "c47ccb34-7267-47f9-d817-3555a243582e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'An easy math task is 2 + 3 = 5. The infix 2 in the word twofold should remain unchanged, though.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.sub(r\"\\btwo\\b\", \"2\", s6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc7e0cc",
      "metadata": {
        "id": "2bc7e0cc"
      },
      "source": [
        "__g)__ Return a list with all elements from the given list that don't contain the letter 'a'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b4e7e6",
      "metadata": {
        "id": "a6b4e7e6"
      },
      "outputs": [],
      "source": [
        "l = [\"apple\", \"cucumber\", \"tomato\", \"zucchini\", \"pumpkin\", \"pear\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67223ef3",
      "metadata": {
        "id": "67223ef3",
        "outputId": "7ec3e6c8-8ff8-42f9-a241-eaac47b777c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cucumber', 'zucchini', 'pumpkin']\n"
          ]
        }
      ],
      "source": [
        "words = [w for w in l if not re.search(r\"a\", w)]\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3f5895",
      "metadata": {
        "id": "da3f5895"
      },
      "source": [
        "### Task 2: Natural Language Toolkit\n",
        "In the next task we're working with the Natural Language Toolkit (NLTK) package of Python, which is a powerful open source library for Natural Language Processing. Make sure you have the package installed and the documentation ready: https://www.nltk.org/api/nltk.html.\n",
        "\n",
        "Then download the Gutenberg corpus and the Punkt sentence tokenization models. `nltk.download()` without parameters provides an interactive interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df2daf9",
      "metadata": {
        "id": "3df2daf9",
        "outputId": "8602cf0b-3404-49ff-e4b3-a634c122932c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to C:\\Users\\Edward\n",
            "[nltk_data]     Gaming\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to C:\\Users\\Edward\n",
            "[nltk_data]     Gaming\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\Edward\n",
            "[nltk_data]     Gaming\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import the NLTK package\n",
        "import nltk\n",
        "\n",
        "# download the Gutenberg corpus\n",
        "nltk.download(\"gutenberg\")\n",
        "# download tokenization models\n",
        "# nltk.download(\"punkt\")\n",
        "# current nltk version requires punkt_tab\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc99eb1",
      "metadata": {
        "id": "ddc99eb1"
      },
      "source": [
        "__a)__ Import the ``gutenberg`` corpus reader from the ``corpus`` module of the ``nltk`` package. What does the Gutenberg corpus contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6768764d",
      "metadata": {
        "id": "6768764d",
        "outputId": "c8140230-c416-404b-d784-9fc14d36d17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Gutenberg Selections\n",
            "http://gutenberg.net/\n",
            "\n",
            "This corpus contains etexts from from Project Gutenberg,\n",
            "by the following authors:\n",
            "\n",
            "* Jane Austen (3)\n",
            "* William Blake (2)\n",
            "* Thornton W. Burgess\n",
            "* Sarah Cone Bryant\n",
            "* Lewis Carroll\n",
            "* G. K. Chesterton (3)\n",
            "* Maria Edgeworth\n",
            "* King James Bible\n",
            "* Herman Melville\n",
            "* John Milton\n",
            "* William Shakespeare (3)\n",
            "* Walt Whitman\n",
            "\n",
            "The beginning of the body of each book could not be identified automatically,\n",
            "so the semi-generic header of each file has been removed, and included below.\n",
            "Some source files ended with a line \"End of The Project Gutenberg Etext...\",\n",
            "and this has been deleted.\n",
            "\n",
            "Information about Project Gutenberg (one page)\n",
            "\n",
            "We produce about two million dollars for each hour we work.  The\n",
            "fifty hours is one conservative estimate for how long it we take\n",
            "to get any etext selected, entered, proofread, edited, copyright\n",
            "searched and analyzed, the copyright letters written, etc.  This\n",
            "projected audience is one hundred million readers.  If our value\n",
            "per text is nominally estimated at one dollar, then we produce 2\n",
            "million dollars per hour this year we, will have to do four text\n",
            "files per month:  thus upping our productivity from one million.\n",
            "The Goal of Project Gutenberg is to Give Away One Trillion Etext\n",
            "Files by the December 31, 2001.  [10,000 x 100,000,000=Trillion]\n",
            "This is ten thousand titles each to one hundred million readers,\n",
            "which is 10% of the expected number of computer users by the end\n",
            "of the year 2001.\n",
            "\n",
            "We need your donations more than ever!\n",
            "\n",
            "All donations should be made to \"Project Gutenberg/IBC\", and are\n",
            "tax deductible to the extent allowable by law (\"IBC\" is Illinois\n",
            "Benedictine College).  (Subscriptions to our paper newsletter go\n",
            "to IBC, too)\n",
            "\n",
            "For these and other matters, please mail to:\n",
            "\n",
            "Project Gutenberg\n",
            "P. O. Box  2782\n",
            "Champaign, IL 61825\n",
            "\n",
            "When all other email fails try our Michael S. Hart, Executive\n",
            "Director:\n",
            "hart@vmd.cso.uiuc.edu (internet)   hart@uiucvmd   (bitnet)\n",
            "\n",
            "We would prefer to send you this information by email\n",
            "(Internet, Bitnet, Compuserve, ATTMAIL or MCImail).\n",
            "\n",
            "******\n",
            "If you have an FTP program (or emulator), please\n",
            "FTP directly to the Project Gutenberg archives:\n",
            "[Mac users, do NOT point and click. . .type]\n",
            "\n",
            "ftp mrcnext.cso.uiuc.edu\n",
            "login:  anonymous\n",
            "password:  your@login\n",
            "cd etext/etext91\n",
            "or cd etext92\n",
            "or cd etext93 [for new books]  [now also in cd etext/etext93]\n",
            "or cd etext/articles [get suggest gut for more information]\n",
            "dir [to see files]\n",
            "get or mget [to get files. . .set bin for zip files]\n",
            "get INDEX100.GUT\n",
            "get INDEX200.GUT\n",
            "for a list of books\n",
            "and\n",
            "get NEW.GUT for general information\n",
            "and\n",
            "mget GUT* for newsletters.\n",
            "\n",
            "**Information prepared by the Project Gutenberg legal advisor**\n",
            "(Three Pages)\n",
            "\n",
            "\n",
            "***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START***\n",
            "Why is this \"Small Print!\" statement here?  You know: lawyers.\n",
            "They tell us you might sue us if there is something wrong with\n",
            "your copy of this etext, even if you got it for free from\n",
            "someone other than us, and even if what's wrong is not our\n",
            "fault.  So, among other things, this \"Small Print!\" statement\n",
            "disclaims most of our liability to you.  It also tells you how\n",
            "you can distribute copies of this etext if you want to.\n",
            "\n",
            "*BEFORE!* YOU USE OR READ THIS ETEXT\n",
            "By using or reading any part of this PROJECT GUTENBERG-tm\n",
            "etext, you indicate that you understand, agree to and accept\n",
            "this \"Small Print!\" statement.  If you do not, you can receive\n",
            "a refund of the money (if any) you paid for this etext by\n",
            "sending a request within 30 days of receiving it to the person\n",
            "you got it from.  If you received this etext on a physical\n",
            "medium (such as a disk), you must return it with your request.\n",
            "\n",
            "ABOUT PROJECT GUTENBERG-TM ETEXTS\n",
            "This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG-\n",
            "tm etexts, is a \"public domain\" work distributed by Professor\n",
            "Michael S. Hart through the Project Gutenberg Association at\n",
            "Illinois Benedictine College (the \"Project\").  Among other\n",
            "things, this means that no one owns a United States copyright\n",
            "on or for this work, so the Project (and you!) can copy and\n",
            "distribute it in the United States without permission and\n",
            "without paying copyright royalties.  Special rules, set forth\n",
            "below, apply if you wish to copy and distribute this etext\n",
            "under the Project's \"PROJECT GUTENBERG\" trademark.\n",
            "\n",
            "To create these etexts, the Project expends considerable\n",
            "efforts to identify, transcribe and proofread public domain\n",
            "works.  Despite these efforts, the Project's etexts and any\n",
            "medium they may be on may contain \"Defects\".  Among other\n",
            "things, Defects may take the form of incomplete, inaccurate or\n",
            "corrupt data, transcription errors, a copyright or other\n",
            "intellectual property infringement, a defective or damaged\n",
            "disk or other etext medium, a computer virus, or computer\n",
            "codes that damage or cannot be read by your equipment.\n",
            "\n",
            "LIMITED WARRANTY; DISCLAIMER OF DAMAGES\n",
            "But for the \"Right of Replacement or Refund\" described below,\n",
            "[1] the Project (and any other party you may receive this\n",
            "etext from as a PROJECT GUTENBERG-tm etext) disclaims all\n",
            "liability to you for damages, costs and expenses, including\n",
            "legal fees, and [2] YOU HAVE NO REMEDIES FOR NEGLIGENCE OR\n",
            "UNDER STRICT LIABILITY, OR FOR BREACH OF WARRANTY OR CONTRACT,\n",
            "INCLUDING BUT NOT LIMITED TO INDIRECT, CONSEQUENTIAL, PUNITIVE\n",
            "OR INCIDENTAL DAMAGES, EVEN IF YOU GIVE NOTICE OF THE\n",
            "POSSIBILITY OF SUCH DAMAGES.\n",
            "\n",
            "If you discover a Defect in this etext within 90 days of\n",
            "receiving it, you can receive a refund of the money (if any)\n",
            "you paid for it by sending an explanatory note within that\n",
            "time to the person you received it from.  If you received it\n",
            "on a physical medium, you must return it with your note, and\n",
            "such person may choose to alternatively give you a replacement\n",
            "copy.  If you received it electronically, such person may\n",
            "choose to alternatively give you a second opportunity to\n",
            "receive it electronically.\n",
            "\n",
            "THIS ETEXT IS OTHERWISE PROVIDED TO YOU \"AS-IS\".  NO OTHER\n",
            "WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, ARE MADE TO YOU AS\n",
            "TO THE ETEXT OR ANY MEDIUM IT MAY BE ON, INCLUDING BUT NOT\n",
            "LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A\n",
            "PARTICULAR PURPOSE.\n",
            "\n",
            "Some states do not allow disclaimers of implied warranties or\n",
            "the exclusion or limitation of consequential damages, so the\n",
            "above disclaimers and exclusions may not apply to you, and you\n",
            "may have other legal rights.\n",
            "\n",
            "INDEMNITY\n",
            "You will indemnify and hold the Project, its directors,\n",
            "officers, members and agents harmless from all liability, cost\n",
            "and expense, including legal fees, that arise directly or\n",
            "indirectly from any of the following that you do or cause:\n",
            "[1] distribution of this etext, [2] alteration, modification,\n",
            "or addition to the etext, or [3] any Defect.\n",
            "\n",
            "DISTRIBUTION UNDER \"PROJECT GUTENBERG-tm\"\n",
            "You may distribute copies of this etext electronically, or by\n",
            "disk, book or any other medium if you either delete this\n",
            "\"Small Print!\" and all other references to Project Gutenberg,\n",
            "or:\n",
            "\n",
            "[1]  Only give exact copies of it.  Among other things, this\n",
            "     requires that you do not remove, alter or modify the\n",
            "     etext or this \"small print!\" statement.  You may however,\n",
            "     if you wish, distribute this etext in machine readable\n",
            "     binary, compressed, mark-up, or proprietary form,\n",
            "     including any form resulting from conversion by word pro-\n",
            "     cessing or hypertext software, but only so long as\n",
            "     *EITHER*:\n",
            "\n",
            "     [*]  The etext, when displayed, is clearly readable, and\n",
            "          does *not* contain characters other than those\n",
            "          intended by the author of the work, although tilde\n",
            "          (~), asterisk (*) and underline (_) characters may\n",
            "          be used to convey punctuation intended by the\n",
            "          author, and additional characters may be used to\n",
            "          indicate hypertext links; OR\n",
            "\n",
            "     [*]  The etext may be readily converted by the reader at\n",
            "          no expense into plain ASCII, EBCDIC or equivalent\n",
            "          form by the program that displays the etext (as is\n",
            "          the case, for instance, with most word processors);\n",
            "          OR\n",
            "\n",
            "     [*]  You provide, or agree to also provide on request at\n",
            "          no additional cost, fee or expense, a copy of the\n",
            "          etext in its original plain ASCII form (or in EBCDIC\n",
            "          or other equivalent proprietary form).\n",
            "\n",
            "[2]  Honor the etext refund and replacement provisions of this\n",
            "     \"Small Print!\" statement.\n",
            "\n",
            "[3]  Pay a trademark license fee to the Project of 20% of the\n",
            "     net profits you derive calculated using the method you\n",
            "     already use to calculate your applicable taxes.  If you\n",
            "     don't derive profits, no royalty is due.  Royalties are\n",
            "     payable to \"Project Gutenberg Association / Illinois\n",
            "     Benedictine College\" within the 60 days following each\n",
            "     date you prepare (or were legally required to prepare)\n",
            "     your annual (or equivalent periodic) tax return.\n",
            "\n",
            "WHAT IF YOU *WANT* TO SEND MONEY EVEN IF YOU DON'T HAVE TO?\n",
            "The Project gratefully accepts contributions in money, time,\n",
            "scanning machines, OCR software, public domain etexts, royalty\n",
            "free copyright licenses, and every other sort of contribution\n",
            "you can think of.  Money should be paid to \"Project Gutenberg\n",
            "Association / Illinois Benedictine College\".\n",
            "\n",
            "This \"Small Print!\" by Charles B. Kramer, Attorney\n",
            "Internet (72600.2026@compuserve.com); TEL: (212-254-5093)\n",
            "*END*THE SMALL PRINT! FOR PUBLIC DOMAIN ETEXTS*Ver.04.29.93*END*\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "print(gutenberg.readme())\n",
        "gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375e10ae",
      "metadata": {
        "id": "375e10ae"
      },
      "source": [
        "__b)__ Have a look at the book \"Persuasion\" by Jane Austen (``austen-persuasion.txt``). Print the number of words and the number of sentences that the book contains. How many unique words can you find? What fraction of sentences contain the word \"Anne\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33d90b3",
      "metadata": {
        "id": "c33d90b3",
        "outputId": "188c02e6-0a04-4eff-fa28-2f30a29f1f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "466292\n",
            "78\n"
          ]
        }
      ],
      "source": [
        "austen = gutenberg.raw(\"austen-persuasion.txt\")\n",
        "print(len(austen))\n",
        "print(len(set(austen)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21dae5d",
      "metadata": {
        "id": "c21dae5d",
        "outputId": "b191d184-21c6-4cda-cfb6-42c1078057ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the number of sentences is 3747\n",
            "477\n"
          ]
        }
      ],
      "source": [
        "aussents = gutenberg.sents(\"austen-persuasion.txt\")\n",
        "print(\"the number of sentences is\", len(aussents))\n",
        "anne = [a for a in aussents if \"Anne\" in a]\n",
        "print(len(anne))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d5167f8",
      "metadata": {
        "id": "7d5167f8"
      },
      "source": [
        "__c)__ By using functions from ``nltk``, tokenize the given text into\n",
        "* words\n",
        "* sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95f9d93",
      "metadata": {
        "id": "d95f9d93"
      },
      "outputs": [],
      "source": [
        "text = \"Tokenize this sentence into sentences and words. This is the task someone gave to you. Why, i.e., what the purpose of this, is remains unknown.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85e5b2a",
      "metadata": {
        "id": "b85e5b2a",
        "outputId": "79acdf46-5f99-4c46-c8e3-f783c349f904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Tokenize this sentence into sentences and words.', 'This is the task someone gave to you.', 'Why, i.e., what the purpose of this, is remains unknown.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "sent1 = sent_tokenize(text)\n",
        "print(sent1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612236bd",
      "metadata": {
        "id": "612236bd",
        "outputId": "bfc8b713-a603-4b4c-de5f-79aef6e7765a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Tokenize', 'this', 'sentence', 'into', 'sentences', 'and', 'words', '.', 'This', 'is', 'the', 'task', 'someone', 'gave', 'to', 'you', '.', 'Why', ',', 'i.e.', ',', 'what', 'the', 'purpose', 'of', 'this', ',', 'is', 'remains', 'unknown', '.']\n"
          ]
        }
      ],
      "source": [
        "word1 = word_tokenize(text)\n",
        "print(word1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8229243c",
      "metadata": {
        "id": "8229243c"
      },
      "source": [
        "__d)__ Use the Porter stemmer from ``nltk`` on the text from task __c)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0982fcc6",
      "metadata": {
        "id": "0982fcc6",
        "outputId": "9b988010-f4e1-4a25-a4b6-7369ebe45f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['token', 'thi', 'sentenc', 'into', 'sentenc', 'and', 'word', '.', 'thi', 'is', 'the', 'task', 'someon', 'gave', 'to', 'you', '.', 'whi', ',', 'i.e.', ',', 'what', 'the', 'purpos', 'of', 'thi', ',', 'is', 'remain', 'unknown', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "p = PorterStemmer()\n",
        "stem1 = [p.stem(w) for w in word1]\n",
        "print(stem1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}