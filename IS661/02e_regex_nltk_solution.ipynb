{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aad2a78",
   "metadata": {},
   "source": [
    "# Exercise 02: Regular Expressions and the Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63068b6",
   "metadata": {},
   "source": [
    "### Task 1: Regular Expressions\n",
    "In this task we're working with the `re` package of Python. Take a look at the documentation to solve the following subtasks: https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695a3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the re package \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce209f79",
   "metadata": {},
   "source": [
    "Make yourself familiar with the different kinds of regex commands `re.XXXX(pattern, string)` available in python. Describe the differences between them.\n",
    "\n",
    "* re.search()\n",
    "* re.match() \n",
    "* re.fullmatch()\n",
    "* re.split()\n",
    "* re.findall() \n",
    "* re.finditer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f90d1f",
   "metadata": {},
   "source": [
    "__Solution__\n",
    "* re.search(): find _first_ match for the pattern in the given string\n",
    "* re.match(): match the pattern only from the _beginning_ of the given string\n",
    "* re.fullmatch(): match only if the _entire_ string corresponds to the pattern\n",
    "* re.split(): _split_ a given string by the pattern\n",
    "* re.findall(): _find all_ (non overlapping) occurences of the pattern, return them as a list\n",
    "* re.finditer(): _find all_ (non overlapping) occurences of the pattern, return them as an _iterator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cd7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 11), match='word'>\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "x = re.search(r'word', 'wor d swords word')\n",
    "print(x)\n",
    "print(x.group()) # Returns one or more subgroups of the match. Without arguments, group1 defaults to zero (the whole match is returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1241850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 0), match=''>\n"
     ]
    }
   ],
   "source": [
    "y1 = re.match(r'word', ' word hello')  # match only at beginning (' ' counts)\n",
    "y2 = re.match(r'', 'hello') # zero characters(empty string) matches as well\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c20c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 4), match='Word'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "z1 = re.fullmatch(r'word', 'Word', flags=re.I)  # re.IGNORECASE\n",
    "z2 = re.fullmatch(r'word', 'Word of hello', flags=re.I)\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ff9a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'b c', '', 'd']\n"
     ]
    }
   ],
   "source": [
    "a = re.split(r'a', 'bab caad')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a507127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'word']\n",
      "['wor', 'd', 'swords', 'word']\n"
     ]
    }
   ],
   "source": [
    "b = re.findall(r'word', 'wor d swords word') \n",
    "c = re.findall(r'\\w+', 'wor d swords word') # \\w+ find all words. \\w = [a-zA-Z0-9_]. + quantifier \"at least once\"\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c795c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x1079891e0>\n",
      "<re.Match object; span=(7, 11), match='word'>\n",
      "<re.Match object; span=(13, 17), match='word'>\n"
     ]
    }
   ],
   "source": [
    "c = re.finditer(r'word', 'wor d swords word') # iterator = stream of data\n",
    "print(c)\n",
    "print(next(c))\n",
    "print(next(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51e9ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 11), match='word'>\n",
      "<re.Match object; span=(13, 17), match='word'>\n"
     ]
    }
   ],
   "source": [
    "c = re.finditer(r'word', 'wor d swords word') \n",
    "for m in c:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860f2dc",
   "metadata": {},
   "source": [
    "__a)__ Write a regular expression that checks if \"Hello World\" is contained in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd13993",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = \"this is a Hello World test \"\n",
    "negative = \"this is a H3ll0 W0rld Test \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960207f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "<re.Match object; span=(10, 21), match='Hello World'>\n",
      "no match\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "print(bool(re.search(r'Hello World', positive)))\n",
    "print(bool(re.search(r'Hello World', negative)))\n",
    "\n",
    "print(re.search(r'hello World', positive, flags=re.I))  # ignore upper/lowercases\n",
    "\n",
    "# or check if != None\n",
    "# or\n",
    "a = re.search(r'Hello World', negative)\n",
    "if a:\n",
    "    print(a.group())\n",
    "else:\n",
    "    print('no match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb00d7",
   "metadata": {},
   "source": [
    "__b)__ Write a regular expression that selects all integer numbers from a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc73173",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"This is a text written in 2022, and it contains numbers like one, 2, 3. Other numbers like 123 are also detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b29ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022', '2', '3', '123']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "re.findall(r'\\d+', s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876c6cf",
   "metadata": {},
   "source": [
    "__c)__ Write a regular expression that finds two (lower-case) words connected by a \"-\" (e.g., ill-advised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62eef05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = \"This my so-so example text. It features well-received meaningless words. The string 1-2 should not be returned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e0149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so-so', 'well-received']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not working: re.findall(r'\\w+-\\w+', s2) \\w also matches numbers and underscores\n",
    "\n",
    "# solution\n",
    "re.findall(r'[a-z]+-[a-z]+', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeeea1",
   "metadata": {},
   "source": [
    "__d)__ Write a regular expression that selects numbers with at least 4 digits from a text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfcdb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"This is a 2022 text, the third useless text I'm writing after 2021 ended. \\\n",
    "    Larger numbers like 63527 should be detected, but smaller numbers like 123 should not.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d620406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022', '2021', '63527']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "re.findall(r'\\d{4,}', s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf603d7",
   "metadata": {},
   "source": [
    "__e)__ Write a regular expression that extract dates in the format YYYY-MM-DD:\n",
    "Assume that Y, M or D are valid when they are digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4641c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = \"2017-05-12 and 2018-01-01 are correct formats,  2017-25-01 is also valid. \\\n",
    "    Not valid is 03.05.22, neither is 12/12/2017.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a068e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-05-12', '2018-01-01', '2017-25-01']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "re.findall(r'\\d{4}-\\d{2}-\\d{2}', s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eded5f",
   "metadata": {},
   "source": [
    "__f)__ Write a regular expression that finds all URLS in a string. For sake of simplicity, a url starts with \"http://\" or \"https://\" and contains at least one dot, which is not at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d61158c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = \"The url http://example1.com should be returned, as well as http://www.example2.com. Let's try http://test.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02a738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = \"The url http://www.exa..mple1.com should be returned, as well as https://www.example2.com. Let's try http://test.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7793f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.exa..mple1.com\n",
      "https://www.example2.com\n"
     ]
    }
   ],
   "source": [
    "for m in re.finditer(r'https?://(\\w*\\.+\\w+)+', s5):\n",
    "    print(m.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e77fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.exa', 'https://www.example2.com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r''' \n",
    "- be careful with the \\. vs .\n",
    "- allow a second dot -> can't use \\w+\\.\\w+\n",
    "- if we want to allow multiple dots directly: re.findall(r'https?://(?:\\w*\\.+\\w+)+', s5)\n",
    "- Note the use of (?:) instead of (): The former indicates a non-capturing group, the latter a capturing group.\n",
    "The result of findall depends on the number of capturing groups in the pattern. If there are no groups, return a list of \n",
    "strings matching the whole pattern. If there is exactly one group, return a list of strings matching that group. \n",
    "If multiple groups are present, return a list of tuples of strings matching the groups. Non-capturing groups do \n",
    "not affect the form of the result.\n",
    "'''\n",
    "\n",
    "re.findall(r'http://(?:\\w*\\.\\w+)+|https://(?:\\w*\\.\\w+)+', s5)  # also works\n",
    "\n",
    "#re.findall(r'https?://(?:\\w*\\.\\w*)+\\w+', s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e7fae68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.example2.com']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strictly speaking, http://www.exa..mple1.com is not a valid URL\n",
    "re.findall(r'(https?://(?:\\w+\\.{1})+\\w+)\\.?\\s', s5) # match valid URLs followed by period (optional) and whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d35428",
   "metadata": {},
   "source": [
    "__g)__ Replace all occurences of _two_ as whole word with _2_ in a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b27cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "s6 = \"An easy math task is two + 3 = 5. The infix two in the word twofold should remain unchanged, though. onetwo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86a1f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An easy math task is 2 + 3 = 5. The infix 2 in the word twofold should remain unchanged, though. onetwo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "re.sub(r'\\btwo\\b', '2', s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7e0cc",
   "metadata": {},
   "source": [
    "__h)__ Return a list with all elements from the given list that don't contain the letter 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6b4e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"apple\", \"cucumber\", \"tomato\", \"zucchini\", \"pumpkin\", \"pear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c8846d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cucumber', 'zucchini', 'pumpkin']\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "l_new = [w for w in l if not re.search(r'a', w)]\n",
    "print(l_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f5895",
   "metadata": {},
   "source": [
    "### Task 2: Natural Language Toolkit\n",
    "In the next task we're working with the Natural Language Toolkit (NLTK) package of Python, which is a powerful open source library for Natural Language Processing. Make sure you have the package installed and the documentation ready: https://www.nltk.org/api/nltk.html.\n",
    "\n",
    "Then download the Gutenberg corpus and the Punkt sentence tokenization models. `nltk.download()` without parameters provides an interactive interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5451a8f6-6a2d-42c8-babe-e03210b03e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the NLTK package\n",
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3df2daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/schloett/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/schloett/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the Gutenberg corpus\n",
    "nltk.download(\"gutenberg\")\n",
    "# download tokenization models\n",
    "# nltk.download(\"punkt\")\n",
    "# current nltk version requires punkt_tab\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc99eb1",
   "metadata": {},
   "source": [
    "__a)__ Import the ``gutenberg`` corpus reader from the ``corpus`` module of the  ``nltk`` package. What does the Gutenberg corpus contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afeb694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg Selections\n",
      "http://gutenberg.net/\n",
      "\n",
      "This corpus contains etexts from from Project Gutenberg,\n",
      "by the following authors:\n",
      "\n",
      "* Jane Austen (3)\n",
      "* William Blake (2)\n",
      "* Thornton W. Burgess\n",
      "* Sarah Cone Bryant\n",
      "* Lewis Carroll\n",
      "* G. K. Chesterton (3)\n",
      "* Maria Edgeworth\n",
      "* King James Bible\n",
      "* Herman Melville\n",
      "* John Milton\n",
      "* William Shakespeare (3)\n",
      "* Walt Whitman\n",
      "\n",
      "The beginning of the body of each book could not be identified automatically,\n",
      "so the semi-generic header of each file has been removed, and included below.\n",
      "Some source files ended with a line \"End of The Project Gutenberg Etext...\",\n",
      "and this has been deleted.\n",
      "\n",
      "Information about Project Gutenberg (one page)\n",
      "\n",
      "We produce about two million dollars for each hour we work.  The\n",
      "fifty hours is one conservative estimate for how long it we take\n",
      "to get any etext selected, entered, proofread, edited, copyright\n",
      "searched and analyzed, the copyright letters written, etc.  This\n",
      "projected audience is one hundred million readers.  If our value\n",
      "per text is nominally estimated at one dollar, then we produce 2\n",
      "million dollars per hour this year we, will have to do four text\n",
      "files per month:  thus upping our productivity from one million.\n",
      "The Goal of Project Gutenberg is to Give Away One Trillion Etext\n",
      "Files by the December 31, 2001.  [10,000 x 100,000,000=Trillion]\n",
      "This is ten thousand titles each to one hundred million readers,\n",
      "which is 10% of the expected number of computer users by the end\n",
      "of the year 2001.\n",
      "\n",
      "We need your donations more than ever!\n",
      "\n",
      "All donations should be made to \"Project Gutenberg/IBC\", and are\n",
      "tax deductible to the extent allowable by law (\"IBC\" is Illinois\n",
      "Benedictine College).  (Subscriptions to our paper newsletter go\n",
      "to IBC, too)\n",
      "\n",
      "For these and other matters, please mail to:\n",
      "\n",
      "Project Gutenberg\n",
      "P. O. Box  2782\n",
      "Champaign, IL 61825\n",
      "\n",
      "When all other email fails try our Michael S. Hart, Executive\n",
      "Director:\n",
      "hart@vmd.cso.uiuc.edu (internet)   hart@uiucvmd   (bitnet)\n",
      "\n",
      "We would prefer to send you this information by email\n",
      "(Internet, Bitnet, Compuserve, ATTMAIL or MCImail).\n",
      "\n",
      "******\n",
      "If you have an FTP program (or emulator), please\n",
      "FTP directly to the Project Gutenberg archives:\n",
      "[Mac users, do NOT point and click. . .type]\n",
      "\n",
      "ftp mrcnext.cso.uiuc.edu\n",
      "login:  anonymous\n",
      "password:  your@login\n",
      "cd etext/etext91\n",
      "or cd etext92\n",
      "or cd etext93 [for new books]  [now also in cd etext/etext93]\n",
      "or cd etext/articles [get suggest gut for more information]\n",
      "dir [to see files]\n",
      "get or mget [to get files. . .set bin for zip files]\n",
      "get INDEX100.GUT\n",
      "get INDEX200.GUT\n",
      "for a list of books\n",
      "and\n",
      "get NEW.GUT for general information\n",
      "and\n",
      "mget GUT* for newsletters.\n",
      "\n",
      "**Information prepared by the Project Gutenberg legal advisor**\n",
      "(Three Pages)\n",
      "\n",
      "\n",
      "***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START***\n",
      "Why is this \"Small Print!\" statement here?  You know: lawyers.\n",
      "They tell us you might sue us if there is something wrong with\n",
      "your copy of this etext, even if you got it for free from\n",
      "someone other than us, and even if what's wrong is not our\n",
      "fault.  So, among other things, this \"Small Print!\" statement\n",
      "disclaims most of our liability to you.  It also tells you how\n",
      "you can distribute copies of this etext if you want to.\n",
      "\n",
      "*BEFORE!* YOU USE OR READ THIS ETEXT\n",
      "By using or reading any part of this PROJECT GUTENBERG-tm\n",
      "etext, you indicate that you understand, agree to and accept\n",
      "this \"Small Print!\" statement.  If you do not, you can receive\n",
      "a refund of the money (if any) you paid for this etext by\n",
      "sending a request within 30 days of receiving it to the person\n",
      "you got it from.  If you received this etext on a physical\n",
      "medium (such as a disk), you must return it with your request.\n",
      "\n",
      "ABOUT PROJECT GUTENBERG-TM ETEXTS\n",
      "This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG-\n",
      "tm etexts, is a \"public domain\" work distributed by Professor\n",
      "Michael S. Hart through the Project Gutenberg Association at\n",
      "Illinois Benedictine College (the \"Project\").  Among other\n",
      "things, this means that no one owns a United States copyright\n",
      "on or for this work, so the Project (and you!) can copy and\n",
      "distribute it in the United States without permission and\n",
      "without paying copyright royalties.  Special rules, set forth\n",
      "below, apply if you wish to copy and distribute this etext\n",
      "under the Project's \"PROJECT GUTENBERG\" trademark.\n",
      "\n",
      "To create these etexts, the Project expends considerable\n",
      "efforts to identify, transcribe and proofread public domain\n",
      "works.  Despite these efforts, the Project's etexts and any\n",
      "medium they may be on may contain \"Defects\".  Among other\n",
      "things, Defects may take the form of incomplete, inaccurate or\n",
      "corrupt data, transcription errors, a copyright or other\n",
      "intellectual property infringement, a defective or damaged\n",
      "disk or other etext medium, a computer virus, or computer\n",
      "codes that damage or cannot be read by your equipment.\n",
      "\n",
      "LIMITED WARRANTY; DISCLAIMER OF DAMAGES\n",
      "But for the \"Right of Replacement or Refund\" described below,\n",
      "[1] the Project (and any other party you may receive this\n",
      "etext from as a PROJECT GUTENBERG-tm etext) disclaims all\n",
      "liability to you for damages, costs and expenses, including\n",
      "legal fees, and [2] YOU HAVE NO REMEDIES FOR NEGLIGENCE OR\n",
      "UNDER STRICT LIABILITY, OR FOR BREACH OF WARRANTY OR CONTRACT,\n",
      "INCLUDING BUT NOT LIMITED TO INDIRECT, CONSEQUENTIAL, PUNITIVE\n",
      "OR INCIDENTAL DAMAGES, EVEN IF YOU GIVE NOTICE OF THE\n",
      "POSSIBILITY OF SUCH DAMAGES.\n",
      "\n",
      "If you discover a Defect in this etext within 90 days of\n",
      "receiving it, you can receive a refund of the money (if any)\n",
      "you paid for it by sending an explanatory note within that\n",
      "time to the person you received it from.  If you received it\n",
      "on a physical medium, you must return it with your note, and\n",
      "such person may choose to alternatively give you a replacement\n",
      "copy.  If you received it electronically, such person may\n",
      "choose to alternatively give you a second opportunity to\n",
      "receive it electronically.\n",
      "\n",
      "THIS ETEXT IS OTHERWISE PROVIDED TO YOU \"AS-IS\".  NO OTHER\n",
      "WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, ARE MADE TO YOU AS\n",
      "TO THE ETEXT OR ANY MEDIUM IT MAY BE ON, INCLUDING BUT NOT\n",
      "LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A\n",
      "PARTICULAR PURPOSE.\n",
      "\n",
      "Some states do not allow disclaimers of implied warranties or\n",
      "the exclusion or limitation of consequential damages, so the\n",
      "above disclaimers and exclusions may not apply to you, and you\n",
      "may have other legal rights.\n",
      "\n",
      "INDEMNITY\n",
      "You will indemnify and hold the Project, its directors,\n",
      "officers, members and agents harmless from all liability, cost\n",
      "and expense, including legal fees, that arise directly or\n",
      "indirectly from any of the following that you do or cause:\n",
      "[1] distribution of this etext, [2] alteration, modification,\n",
      "or addition to the etext, or [3] any Defect.\n",
      "\n",
      "DISTRIBUTION UNDER \"PROJECT GUTENBERG-tm\"\n",
      "You may distribute copies of this etext electronically, or by\n",
      "disk, book or any other medium if you either delete this\n",
      "\"Small Print!\" and all other references to Project Gutenberg,\n",
      "or:\n",
      "\n",
      "[1]  Only give exact copies of it.  Among other things, this\n",
      "     requires that you do not remove, alter or modify the\n",
      "     etext or this \"small print!\" statement.  You may however,\n",
      "     if you wish, distribute this etext in machine readable\n",
      "     binary, compressed, mark-up, or proprietary form,\n",
      "     including any form resulting from conversion by word pro-\n",
      "     cessing or hypertext software, but only so long as\n",
      "     *EITHER*:\n",
      "\n",
      "     [*]  The etext, when displayed, is clearly readable, and\n",
      "          does *not* contain characters other than those\n",
      "          intended by the author of the work, although tilde\n",
      "          (~), asterisk (*) and underline (_) characters may\n",
      "          be used to convey punctuation intended by the\n",
      "          author, and additional characters may be used to\n",
      "          indicate hypertext links; OR\n",
      "\n",
      "     [*]  The etext may be readily converted by the reader at\n",
      "          no expense into plain ASCII, EBCDIC or equivalent\n",
      "          form by the program that displays the etext (as is\n",
      "          the case, for instance, with most word processors);\n",
      "          OR\n",
      "\n",
      "     [*]  You provide, or agree to also provide on request at\n",
      "          no additional cost, fee or expense, a copy of the\n",
      "          etext in its original plain ASCII form (or in EBCDIC\n",
      "          or other equivalent proprietary form).\n",
      "\n",
      "[2]  Honor the etext refund and replacement provisions of this\n",
      "     \"Small Print!\" statement.\n",
      "\n",
      "[3]  Pay a trademark license fee to the Project of 20% of the\n",
      "     net profits you derive calculated using the method you\n",
      "     already use to calculate your applicable taxes.  If you\n",
      "     don't derive profits, no royalty is due.  Royalties are\n",
      "     payable to \"Project Gutenberg Association / Illinois\n",
      "     Benedictine College\" within the 60 days following each\n",
      "     date you prepare (or were legally required to prepare)\n",
      "     your annual (or equivalent periodic) tax return.\n",
      "\n",
      "WHAT IF YOU *WANT* TO SEND MONEY EVEN IF YOU DON'T HAVE TO?\n",
      "The Project gratefully accepts contributions in money, time,\n",
      "scanning machines, OCR software, public domain etexts, royalty\n",
      "free copyright licenses, and every other sort of contribution\n",
      "you can think of.  Money should be paid to \"Project Gutenberg\n",
      "Association / Illinois Benedictine College\".\n",
      "\n",
      "This \"Small Print!\" by Charles B. Kramer, Attorney\n",
      "Internet (72600.2026@compuserve.com); TEL: (212-254-5093)\n",
      "*END*THE SMALL PRINT! FOR PUBLIC DOMAIN ETEXTS*Ver.04.29.93*END*\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import corpus reader \n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# https://www.nltk.org/howto/corpus.html\n",
    "\n",
    "# have a look at the readme file\n",
    "print(gutenberg.readme())\n",
    "\n",
    "# have a look at the files of the corpus\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e10ae",
   "metadata": {},
   "source": [
    "__b)__ Have a look at the book \"Persuasion\" by Jane Austen (``austen-persuasion.txt``). Print the number of words and the number of sentences that the book contains. How many unique words can you find? What fraction of sentences contain the word \"Anne\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce5c71bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Persuasion by Jane Austen 1818]\n",
      "\n",
      "\n",
      "Chapter 1\n",
      "\n",
      "\n",
      "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
      "for his own amusement, never took up any book but the Baronetage;\n",
      "there he found occupation for an idle hour, and consolation in a\n",
      "distressed one; there his faculties were roused into admiration and\n",
      "respect, by contemplating the limited remnant of the earliest patents;\n",
      "there any unwelcome sensations, arising from domestic affairs\n",
      "changed naturally into pity and contempt as he turned over\n",
      "the almost endless creations of the last century; and there,\n",
      "if every other leaf were powerless, he could read his own history\n",
      "with an interest which never failed.  This was the page at which\n",
      "the favourite volume always opened:\n",
      "\n",
      "           \"ELLIOT OF KELLYNCH HALL.\n",
      "\n",
      "\"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth,\n",
      "daughter of James Stevenson, Esq. of South Park, in the county of\n",
      "Gloucester, by which lady (who died 1800) he has issue Elizabeth,\n",
      "born June 1, 1785; Anne, born August 9, 1787; a still-born son,\n",
      "November 5, 1789; Mary, born November 20, 1791.\"\n",
      "466292\n"
     ]
    }
   ],
   "source": [
    "# The book \"Persuasion\" by Jane Austen as raw text\n",
    "raw = gutenberg.raw('austen-persuasion.txt')\n",
    "\n",
    "print(raw[:1090])\n",
    "# the length of the raw text is the number of letters icluding spaces\n",
    "print(len(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "911742db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ']', 'Chapter', '1', 'Sir']\n",
      "98171\n",
      "6132\n"
     ]
    }
   ],
   "source": [
    "# get all tokens as a list\n",
    "words = gutenberg.words('austen-persuasion.txt')\n",
    "\n",
    "print(words[:10])\n",
    "\n",
    "# number of words\n",
    "print(len(words))\n",
    "\n",
    "# number of unique words (including punctuation marks)\n",
    "print(len(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55c29638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Persuasion by Jane Austen 1818 ]', 'Chapter 1', 'Sir Walter Elliot , of Kellynch Hall , in Somersetshire , was a man who , for his own amusement , never took up any book but the Baronetage ; there he found occupation for an idle hour , and consolation in a distressed one ; there his faculties were roused into admiration and respect , by contemplating the limited remnant of the earliest patents ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century ; and there , if every other leaf were powerless , he could read his own history with an interest which never failed .']\n",
      "number of sentences: 3747\n",
      "477\n",
      "0.12730184147317855\n"
     ]
    }
   ],
   "source": [
    "sents = gutenberg.sents('austen-persuasion.txt')\n",
    "\n",
    "# first 3 sentences\n",
    "print([' '.join(s) for s in sents[:3]])\n",
    "\n",
    "# number of sentences\n",
    "print('number of sentences:', len(sents))\n",
    "\n",
    "# fraction of sentences that contain the word \"Anne\"\n",
    "sents_anne = [s for s in sents if 'Anne' in s]\n",
    "print(len(sents_anne))\n",
    "\n",
    "print(len(sents_anne)/len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5167f8",
   "metadata": {},
   "source": [
    "__c)__ By using functions from ``nltk``, tokenize the given text into\n",
    "* words\n",
    "* sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d95f9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenize this sentence into sentences and words. This is the task someone gave to you. \\\n",
    "    Why, i.e., what the purpose of this is, remains unknown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ed6f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenize this sentence into sentences and words.', 'This is the task someone gave to you.', 'Why, i.e., what the purpose of this is, remains unknown.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# tokenize into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f79ec62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenize', 'this', 'sentence', 'into', 'sentences', 'and', 'words', '.', 'This', 'is', 'the', 'task', 'someone', 'gave', 'to', 'you', '.', 'Why', ',', 'i.e.', ',', 'what', 'the', 'purpose', 'of', 'this', 'is', ',', 'remains', 'unknown', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenize into words\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229243c",
   "metadata": {},
   "source": [
    "__d)__ Use the Porter stemmer from ``nltk`` on the text from task __c)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "578e664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'thi', 'sentenc', 'into', 'sentenc', 'and', 'word', '.', 'thi', 'is', 'the', 'task', 'someon', 'gave', 'to', 'you', '.', 'whi', ',', 'i.e.', ',', 'what', 'the', 'purpos', 'of', 'thi', 'is', ',', 'remain', 'unknown', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "p = PorterStemmer()\n",
    "stems = [p.stem(word) for word in words]\n",
    "print(stems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
